
- test code added to btree/table.rs using a multilevel table integration test. Also add the untracked 3 level db resource files.
- Test that it can walk the whole "multipage" table.
- Testing with a 3 level table, which we have.

Little Cleanups:
- As of Rust 1.32, the standard numeric types provide built-in methods like to_le_bytes and from_le_bytes,
  which support some of the same use cases as byteorder.  Consider using those.  Esp in dbheader.rs, but other places too.
- Rewrite most of the methods in dbheader as single-field accessors rather than defining the header as an object.

TODO LATER: 
- testing for query execution can mostly use fake tables, like joins, range queries, index use, and so on.  A real table 
  and a btreemap can both implement the same traits, and the scanners and selectors and so on should only care about these
  traits.

TODO LATER:
- decide how to handle spilled payloads.
    - Make a copy eagerly ... how to make the accessor take that memory ... lifetimes.
    - Provide lazy access to the data through a spilled string iterator?  -- Holds locks on the spill page too?  Gets complex?
    - Expose via enum { CompleteString, SpilledString }, complicating callers.
    - Have the iterator own a heap allocation that contains a clone, but only when necessary. *like*
    - Have the iterator return a text/blob iterator that knows how to iterate over the split, with string/slice-like Traits *like*


TODO LATER:
- We will eventually need all of:
    - table locking (when e.g. changing the definition of a table schema)
    - btree locking (when growing/shrinking the btree (this might take the form of just locking certain pages?))
    - single page locking (when modifying a value in a row) - several rows can be modified concurrently.
- Are Indexes children of the Table, since they need to be updated in sync with the table?

TODO Later: 
- Build Parse Tree / IR from queries.
- Start by representing a select * from T as Scan(T).
- Add Project when it is a list of columns rather than just a '*'. (Project(cols) <- Scan(T))
- Add arithmetic expressions in the Project . 
- Add filter for Where (Filter(expr) -> Project(cols) <- Scan(T)
- Apply rules to reorder the tree (e.g. when the where is simple, convert the Scan(T) to Lookup(T) and push that down from Filter)
- Take inspiration from https://www.querifylabs.com/blog/relational-operators-in-apache-calcite

Things that have been useful to think about:
  - Reminding myself that the lifetime specifier is not the "places where this reference is used" (scope).
    Rather it is the lifetime of the variable (referrent).  In one failed attempt, I added more bounds for a type with several
    references, but actually both references were to the same variable (the pager and its data).
  - This blog goes over tree traversals: https://sachanganesh.com/programming/graph-tree-traversals-in-rust/
    They do several things:
    - They don't store the references to the data in the stack for the inorder traversal. 
      They just store the references to the page numbers.
      - Would this help us?  Need to think how transactions would work.  Do we try to lock all the pages we need for read as we go,
        and then succeed if we get them all?
    - They use an arena allocator where all the memory has a lifetime longer than the traversal (same with my pager.)
